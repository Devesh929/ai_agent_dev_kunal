{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9854ea",
   "metadata": {},
   "source": [
    "# üß™ Data Profiling Assignment: Getting Hands-On with Real-World Stats\n",
    "\n",
    "Welcome! This assignment is designed to help you **play with data like working analysts do**. You‚Äôll explore a synthetic dataset with **thousands of points** and analyze it using:\n",
    "\n",
    "- **Central tendency**: mean, median, (estimated) mode\n",
    "- **Dispersion**: variance, standard deviation, coefficient of variation (CV), range, IQR\n",
    "- **Shape**: skewness, kurtosis\n",
    "- **Position & extremes**: min, max, percentiles, z-scores\n",
    "- **Distribution rules**: Empirical Rule (68‚Äì95‚Äì99.7) & Chebyshev‚Äôs inequality\n",
    "\n",
    "Each question asks you to **use the sample data** to compute something and **explain what it means**. After every question you‚Äôll find **two blank cells**: one for code, one for your interpretation.\n",
    "\n",
    "**Tip:** In professional work, the numbers are just the start‚Äî**the story** they tell is what matters. Be explicit about assumptions, limitations, and what a stakeholder should take away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8103f7",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b87821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(edgeitems=3, linewidth=120)\n",
    "pd.set_option('display.width', 120)\n",
    "pd.set_option('display.max_columns', 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156050ea",
   "metadata": {},
   "source": [
    "## 2) Generate a Sample Dataset (thousands of points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3bdbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal</th>\n",
       "      <th>lognormal</th>\n",
       "      <th>t_df3</th>\n",
       "      <th>uniform</th>\n",
       "      <th>exponential</th>\n",
       "      <th>bimodal</th>\n",
       "      <th>with_outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304717</td>\n",
       "      <td>0.792822</td>\n",
       "      <td>0.138433</td>\n",
       "      <td>-0.045096</td>\n",
       "      <td>2.049361</td>\n",
       "      <td>-2.145103</td>\n",
       "      <td>-0.651898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.039984</td>\n",
       "      <td>0.763733</td>\n",
       "      <td>-0.229852</td>\n",
       "      <td>2.703969</td>\n",
       "      <td>1.891653</td>\n",
       "      <td>-1.722417</td>\n",
       "      <td>-1.579549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750451</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>4.519477</td>\n",
       "      <td>1.059963</td>\n",
       "      <td>2.327707</td>\n",
       "      <td>-2.224025</td>\n",
       "      <td>0.646698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.940565</td>\n",
       "      <td>1.470547</td>\n",
       "      <td>0.611817</td>\n",
       "      <td>0.513368</td>\n",
       "      <td>1.365464</td>\n",
       "      <td>-2.376502</td>\n",
       "      <td>-0.319862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.951035</td>\n",
       "      <td>1.235137</td>\n",
       "      <td>0.332825</td>\n",
       "      <td>-1.044643</td>\n",
       "      <td>0.389808</td>\n",
       "      <td>-2.328547</td>\n",
       "      <td>-1.262942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     normal  lognormal     t_df3   uniform  exponential   bimodal  with_outliers\n",
       "0  0.304717   0.792822  0.138433 -0.045096     2.049361 -2.145103      -0.651898\n",
       "1 -1.039984   0.763733 -0.229852  2.703969     1.891653 -1.722417      -1.579549\n",
       "2  0.750451   0.534195  4.519477  1.059963     2.327707 -2.224025       0.646698\n",
       "3  0.940565   1.470547  0.611817  0.513368     1.365464 -2.376502      -0.319862\n",
       "4 -1.951035   1.235137  0.332825 -1.044643     0.389808 -2.328547      -1.262942"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducible synthetic data that mimics different real-world shapes\n",
    "rng = np.random.default_rng(42)\n",
    "n = 5000  # thousands of points\n",
    "\n",
    "# Distributions\n",
    "normal = rng.normal(0, 1, n)  # symmetric, light tails\n",
    "lognormal = rng.lognormal(mean=0.0, sigma=0.9, size=n)  # positive, right-skewed\n",
    "t_df3 = rng.standard_t(df=3, size=n)  # symmetric, heavy tails\n",
    "uniform = rng.uniform(-3, 3, size=n)  # flat\n",
    "exponential = rng.exponential(scale=1.0, size=n)  # positive, right-skewed\n",
    "\n",
    "# Bimodal mixture\n",
    "bimodal = np.concatenate([\n",
    "    rng.normal(-2.0, 0.5, n // 2),\n",
    "    rng.normal( 2.0, 0.5, n - n // 2)\n",
    "])\n",
    "\n",
    "# Normal with a few extreme outliers injected\n",
    "with_outliers = rng.normal(0, 1, n)\n",
    "out_idx = rng.choice(n, size=12, replace=False)\n",
    "with_outliers[out_idx] = rng.normal(0, 1, size=12) * 10\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'normal': normal,\n",
    "    'lognormal': lognormal,\n",
    "    't_df3': t_df3,\n",
    "    'uniform': uniform,\n",
    "    'exponential': exponential,\n",
    "    'bimodal': bimodal,\n",
    "    'with_outliers': with_outliers,\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54510f",
   "metadata": {},
   "source": [
    "### Quick peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e95c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>-0.019877</td>\n",
       "      <td>0.999454</td>\n",
       "      <td>-3.648413</td>\n",
       "      <td>-0.691954</td>\n",
       "      <td>-0.004161</td>\n",
       "      <td>0.631247</td>\n",
       "      <td>3.454046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lognormal</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>1.515106</td>\n",
       "      <td>1.746572</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.551296</td>\n",
       "      <td>0.982112</td>\n",
       "      <td>1.831378</td>\n",
       "      <td>37.458799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_df3</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>1.652612</td>\n",
       "      <td>-12.577299</td>\n",
       "      <td>-0.742290</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.765586</td>\n",
       "      <td>30.190838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>1.719777</td>\n",
       "      <td>-2.999717</td>\n",
       "      <td>-1.448413</td>\n",
       "      <td>0.029373</td>\n",
       "      <td>1.530037</td>\n",
       "      <td>2.999743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exponential</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.995986</td>\n",
       "      <td>0.993266</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.278624</td>\n",
       "      <td>0.696891</td>\n",
       "      <td>1.374293</td>\n",
       "      <td>7.766503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bimodal</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>-0.011055</td>\n",
       "      <td>2.053284</td>\n",
       "      <td>-3.798815</td>\n",
       "      <td>-2.000615</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>1.972950</td>\n",
       "      <td>4.163460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with_outliers</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.013223</td>\n",
       "      <td>1.130575</td>\n",
       "      <td>-5.917001</td>\n",
       "      <td>-0.667940</td>\n",
       "      <td>-0.001768</td>\n",
       "      <td>0.673869</td>\n",
       "      <td>20.732260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean       std        min       25%       50%       75%        max\n",
       "normal         5000.0 -0.019877  0.999454  -3.648413 -0.691954 -0.004161  0.631247   3.454046\n",
       "lognormal      5000.0  1.515106  1.746572   0.019251  0.551296  0.982112  1.831378  37.458799\n",
       "t_df3          5000.0  0.028603  1.652612 -12.577299 -0.742290  0.010486  0.765586  30.190838\n",
       "uniform        5000.0  0.038330  1.719777  -2.999717 -1.448413  0.029373  1.530037   2.999743\n",
       "exponential    5000.0  0.995986  0.993266   0.000030  0.278624  0.696891  1.374293   7.766503\n",
       "bimodal        5000.0 -0.011055  2.053284  -3.798815 -2.000615  0.003059  1.972950   4.163460\n",
       "with_outliers  5000.0  0.013223  1.130575  -5.917001 -0.667940 -0.001768  0.673869  20.732260"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73076cdc",
   "metadata": {},
   "source": [
    "> Optional: Save a copy as CSV so you (or a teammate) can reuse the same snapshot later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ef7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sample_data.csv', index=False)\n",
    "print('Saved sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ded4b",
   "metadata": {},
   "source": [
    "## 3) Helper Utilities (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficient_of_variation(x: pd.Series):\n",
    "    \"\"\"CV = sample std / mean. Not meaningful when mean‚âà0 or for variables taking negative values.\n",
    "    Returns np.nan if mean is too close to zero.\n",
    "    \"\"\"\n",
    "    m = x.mean()\n",
    "    s = x.std(ddof=1)\n",
    "    return np.nan if np.isclose(m, 0.0) else s / m\n",
    "\n",
    "def empirical_within_k(x: pd.Series, k: int):\n",
    "    m, s = x.mean(), x.std(ddof=1)\n",
    "    if np.isclose(s, 0.0):\n",
    "        return np.nan\n",
    "    z = (x - m) / s\n",
    "    return (np.abs(z) <= k).mean()\n",
    "\n",
    "def chebyshev_lower_bound(k: int):\n",
    "    assert k >= 1\n",
    "    return 1 - 1 / (k**2)\n",
    "\n",
    "def z_scores(x: pd.Series):\n",
    "    return (x - x.mean()) / x.std(ddof=1)\n",
    "\n",
    "def hist_and_qq(x: pd.Series, bins=50, title=''):\n",
    "    \"\"\"Simple visuals to reason about shape (run when needed).\"\"\"\n",
    "    plt.figure()\n",
    "    plt.hist(x.values, bins=bins)\n",
    "    plt.title(f'Histogram: {title}')\n",
    "    plt.xlabel('value'); plt.ylabel('count')\n",
    "    plt.show()\n",
    "\n",
    "    # Q-Q plot against normal to assess normality / tails\n",
    "    plt.figure()\n",
    "    stats.probplot(x, dist='norm', plot=plt)\n",
    "    plt.title(f'Normal Q-Q: {title}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b7cbfd",
   "metadata": {},
   "source": [
    "# Section A ‚Äî Central Tendency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b322c40",
   "metadata": {},
   "source": [
    "### A1. Mean vs Median (and an estimate of Mode)\n",
    "\n",
    "Pick **two columns**‚Äîone roughly symmetric (e.g., `normal`) and one skewed (e.g., `lognormal` or `exponential`).\n",
    "\n",
    "1) Compute the **mean** and **median** for each.\n",
    "2) Provide a **rough estimate of the mode** (e.g., from the mid-point of the most populated histogram bin).\n",
    "3) Explain the **ordering** you see (mean vs median vs mode) and what it implies about **symmetry/skewness**.\n",
    "4) In a business context, when would you prefer **median** over **mean**, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d2202",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c596be6",
   "metadata": {},
   "source": [
    "### A2. Robustness to Outliers\n",
    "\n",
    "Using the `with_outliers` column:\n",
    "\n",
    "1) Compute the mean and median **before** and **after** trimming the top/bottom 1% (use percentiles).\n",
    "2) Which statistic is **more robust** to the injected extremes? Explain.\n",
    "3) Why might stakeholders be misled by the mean here? Provide a short note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899bc48",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4fac13",
   "metadata": {},
   "source": [
    "# Section B ‚Äî Dispersion (Spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1212f53e",
   "metadata": {},
   "source": [
    "### B1. Variance, Standard Deviation, Range, and IQR\n",
    "\n",
    "For **at least three columns** (suggestion: `normal`, `t_df3`, `with_outliers`):\n",
    "\n",
    "1) Compute **variance**, **standard deviation**, **range** (max‚àímin), and **IQR** (Q3‚àíQ1).\n",
    "2) Interpret how **outliers** and **heavy tails** change these measures.\n",
    "3) Who would care about this in practice (e.g., risk teams, operations, product)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abda428",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81e2fe2",
   "metadata": {},
   "source": [
    "### B2. Coefficient of Variation (CV)\n",
    "\n",
    "For **positive-valued** columns (e.g., `lognormal`, `exponential`):\n",
    "\n",
    "1) Compute **CV = std/mean**.\n",
    "2) Rank the selected columns by CV.\n",
    "3) Explain when CV is **not appropriate** (hint: mean‚âà0 or sign changes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bf756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197ab0c",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed1d77",
   "metadata": {},
   "source": [
    "# Section C ‚Äî Shape of the Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9f1a25",
   "metadata": {},
   "source": [
    "### C1. Skewness & Kurtosis\n",
    "\n",
    "Across **all columns**:\n",
    "\n",
    "1) Compute **skewness** and **(excess) kurtosis** (use `scipy.stats.skew` and `scipy.stats.kurtosis(fisher=True)`).\n",
    "2) Identify which distributions are **right/left-skewed**.\n",
    "3) Which have **heavy tails** (excess kurtosis > 0)? How does that show up in the Q-Q plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62f2d0",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45d0a70",
   "metadata": {},
   "source": [
    "### C2. Visual Intuition Check\n",
    "\n",
    "Pick **two columns** with different shapes (e.g., `normal` vs `bimodal`).\n",
    "\n",
    "1) Plot a histogram and a normal Q-Q plot for each (use `hist_and_qq`).\n",
    "2) Explain **why** percentiles or averages alone can miss **multimodality**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2002f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d0011",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b72683",
   "metadata": {},
   "source": [
    "# Section D ‚Äî Position & Extremes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e509387b",
   "metadata": {},
   "source": [
    "### D1. Min/Max & Percentiles\n",
    "\n",
    "For **each column**:\n",
    "\n",
    "1) Report **min**, **max**, and key **percentiles** (1st, 5th, 25th, 50th, 75th, 95th, 99th).\n",
    "2) Which columns show the **widest spread** between the 1st and 99th percentiles?\n",
    "3) What operational risks might that imply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09b1b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e51d6",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39fe12",
   "metadata": {},
   "source": [
    "### D2. Z-Scores & Outlier Flagging\n",
    "\n",
    "Using the `with_outliers` column:\n",
    "\n",
    "1) Compute **z-scores** and count points with **|z| > 3**.\n",
    "2) Show the **indices** (or values) of these potential outliers.\n",
    "3) Explain the difference between **statistical outliers** and **bad data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ca760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be0d04",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae822d09",
   "metadata": {},
   "source": [
    "# Section E ‚Äî Distribution Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138f6f51",
   "metadata": {},
   "source": [
    "### E1. Empirical Rule (68‚Äì95‚Äì99.7)\n",
    "\n",
    "For `normal` and `t_df3`:\n",
    "\n",
    "1) Compute the **proportion of points** within **1, 2, and 3** standard deviations of the mean.\n",
    "2) Compare to **68% / 95% / 99.7%**. Where does it **match or break down**, and why?\n",
    "3) What decision mistakes might happen if someone assumes normality where it doesn‚Äôt hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14515548",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984d4ec",
   "metadata": {},
   "source": [
    "### E2. Chebyshev‚Äôs Inequality (distribution-free bound)\n",
    "\n",
    "Pick any **three columns**:\n",
    "\n",
    "1) For **k = 2 and 3**, compute Chebyshev‚Äôs **lower bound** (‚â• 1 ‚àí 1/k¬≤) for the proportion within k SDs.\n",
    "2) Compute the **actual proportions** and compare to the bounds.\n",
    "3) Explain why Chebyshev‚Äôs bound can be **loose** but still **useful** in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8f17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4647ba",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8167c1",
   "metadata": {},
   "source": [
    "# Section F ‚Äî Synthesis & Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4eb10",
   "metadata": {},
   "source": [
    "### F1. Tell the Data Story\n",
    "\n",
    "Choose **two columns** with contrasting behavior (e.g., `lognormal` vs `t_df3`).\n",
    "\n",
    "Write a short **executive-style note** (5‚Äì10 sentences) for a non-technical stakeholder that explains:\n",
    "- Central tendency: which typical value is most representative and why\n",
    "- Spread: what volatility/risk is present and how you‚Äôd summarize it\n",
    "- Shape: skew/tails and what they mean for planning\n",
    "- Extremes: what to expect in the worst 1‚Äì5% of cases\n",
    "- Any **actionable recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72942ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a3328",
   "metadata": {},
   "source": [
    "_Use this cell for your interpretation/short write-up._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df019302",
   "metadata": {},
   "source": [
    "---\n",
    "### Submission Checklist\n",
    "- Run all cells in order.\n",
    "- Ensure each question has code + a short written interpretation.\n",
    "- If you add extra visualizations or helper functions, briefly justify them.\n",
    "\n",
    "Good luck & have fun exploring! üßë‚Äçüíªüìä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
