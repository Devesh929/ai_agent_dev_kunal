{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SEC 10-K RAG (Apple 2024 + Tesla 2023) — Colab Notebook\n",
        "\n",
        "This notebook runs the full assignment pipeline:\n",
        "- Upload PDFs\n",
        "- Build FAISS index (embeddings)\n",
        "- Retrieve top-5 + rerank\n",
        "- Generate answers via **vLLM** (local/open LLM)\n",
        "- Export `predictions.json`\n",
        "\n",
        "**Tip:** Use a GPU runtime: *Runtime → Change runtime type → GPU*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "GITHUB_REPO_URL = \"https://github.com/<you>/<your-repo>.git\"\n",
        "!rm -rf sec_rag_vllm\n",
        "!git clone {GITHUB_REPO_URL} sec_rag_vllm\n",
        "%cd sec_rag_vllm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip -q install -r requirements.txt\n",
        "!pip -q install -r requirements-gpu-vllm.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Upload the PDFs\n",
        "Upload the two filings PDFs:\n",
        "- Apple 2024 10-K PDF\n",
        "- Tesla 2023 10-K PDF\n",
        "\n",
        "They will be copied into `data/` as:\n",
        "- `data/10-Q4-2024-As-Filed.pdf`\n",
        "- `data/tsla-20231231-gen.pdf`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "Path('data').mkdir(exist_ok=True)\n",
        "uploaded_pdfs = files.upload()\n",
        "\n",
        "# Heuristic rename based on filename\n",
        "apple_out = Path('data/10-Q4-2024-As-Filed.pdf')\n",
        "tesla_out = Path('data/tsla-20231231-gen.pdf')\n",
        "\n",
        "for fname in uploaded_pdfs.keys():\n",
        "    if not fname.lower().endswith('.pdf'):\n",
        "        continue\n",
        "    lower = fname.lower()\n",
        "    src = Path(fname)\n",
        "    if 'tesla' in lower or 'tsla' in lower:\n",
        "        shutil.copy(src, tesla_out)\n",
        "        print('Saved Tesla PDF ->', tesla_out)\n",
        "    elif 'apple' in lower or '10-q4-2024' in lower or 'q4-2024' in lower:\n",
        "        shutil.copy(src, apple_out)\n",
        "        print('Saved Apple PDF ->', apple_out)\n",
        "    else:\n",
        "        # If ambiguous, ask you to rename locally and re-upload; but we'll still keep it for manual move.\n",
        "        dst = Path('data') / fname\n",
        "        shutil.copy(src, dst)\n",
        "        print('Saved unknown PDF ->', dst)\n",
        "\n",
        "assert apple_out.exists(), 'Apple PDF not found in data/. Make sure you uploaded the Apple 10-K.'\n",
        "assert tesla_out.exists(), 'Tesla PDF not found in data/. Make sure you uploaded the Tesla 10-K.'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure the LLM\n",
        "Set `RAG_LLM_MODEL` to an open-access instruct model supported by vLLM.\n",
        "\n",
        "Good default for Colab GPUs: `microsoft/Phi-3-mini-4k-instruct`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Choose your model (open-access)\n",
        "os.environ['RAG_LLM_MODEL'] = os.environ.get('RAG_LLM_MODEL', 'microsoft/Phi-3-mini-4k-instruct')\n",
        "\n",
        "# Where the index will be stored\n",
        "os.environ['RAG_INDEX_DIR'] = os.environ.get('RAG_INDEX_DIR', 'index')\n",
        "\n",
        "print('RAG_LLM_MODEL =', os.environ['RAG_LLM_MODEL'])\n",
        "print('RAG_INDEX_DIR =', os.environ['RAG_INDEX_DIR'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the index (PDF → chunks → embeddings → FAISS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m rag_sec.cli ingest --data-dir data --index-dir index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run evaluation (13 questions) and export predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m rag_sec.cli eval --index-dir index --out outputs/predictions.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "pred_path = Path('outputs/predictions.json')\n",
        "print('Saved:', pred_path.resolve())\n",
        "preds = json.loads(pred_path.read_text())\n",
        "preds[:3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive: call `answer_question(query)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rag_sec import answer_question\n",
        "\n",
        "answer_question('What was Apples total revenue for the fiscal year ended September 28, 2024?')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('outputs/predictions.json')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "SEC_10K_RAG_vLLM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
